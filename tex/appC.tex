\chapter{Tessellation Service Documentation}
\label{secC}
The TS is openly available at GitHub and comes with instructions for usage and installation. The Repository can be found at:

\url{https://github.com/SasNaw/TessellationService}

\section{Main}

\subsubsection{run(input)}
As stated in section \ref{sec5_method}, each input element can be a file or a dictionary. Therefore, the individual entries must be examined. The \texttt{run(input)} function does exactly that. Each element's type (file or directory) is checked. If it is a file, the extraction process is started (line 8). If it is a directory, its files and subdirectories are extracted (line 5).

\begin{lstlisting}[frame=single,language=python]
def run(input):
	for element in input:
		# input is folder:
		if(os.path.isdir(element)):
			files_from_dir(element)
		# input is file:
		elif(os.path.isfile(element)):
			regions_from_file(element)
\end{lstlisting}


\subsubsection{files{\textunderscore}from{\textunderscore}dir(element)}
\texttt{files{\textunderscore}from{\textunderscore}dir(element)} gets the content of the provided directory (line 4). For every subdirectory found, \texttt{files{\textunderscore}from{\textunderscore}dir(element)} is called recursively, until the end of each directory tree is reached. An exception from this are the DZI \emph{"{\textunderscore}files"} directories, since they only contain the corresponding DZI's tessellated image levels (line 6 - 8). If a file was found, the extraction process is started for it (line 9 - 10).

\begin{lstlisting}[frame=single,language=python]
def files_from_dir(dir):
	if not dir.endswith('/'):
		dir = dir + '/'
	contents = os.listdir(dir)
	for content in contents:
		if os.path.isdir(dir + content):
			if not content.endswith('_files'):
				files_from_dir(dir + content)
		else:
			regions_from_file(dir + content)
\end{lstlisting}


\subsubsection{regions{\textunderscore}from{\textunderscore}file(element)}
Since the implementation for WSI and DZI differs, a distinction must be made, which of two approaches is chosen. \texttt{regions{\textunderscore}from{\textunderscore}file(element)} makes this distinction and starts the extraction process for the provided element. If the provided element is not of the DZI type, it is checked if it is a valid WSI (via \texttt{is{\textunderscore}supported(file)}, see line 5) before the process is started. This way, only DZI and WSI will be targeted with extraction attempts.
\begin{lstlisting}[frame=single,language=python]
def regions_from_file(file):
	if file.endswith('.dzi'):
		dzi(file)
	else:
		if(is_suppoted(file)):
			wsi(file)
\end{lstlisting}


\section{WSI}

\subsubsection{wsi(file)}
\texttt{wsi(file)} extracts the regions from a WSI. To do so, the provided file must have an associated JSON file which was annotated with the dictionary provided as argument when the TS was started\footnote{
	Compare subsection \ref{sec5_exec}
}.

OpenSlide is used to read the provided WSI (see line 2). The file name is extracted from the file path (see line 3). The saved regions are loaded and parsed via \texttt{read{\textunderscore}json(path)} function (see line 4).

For each parsed region, an image is extracted together with a metadata file. If the tessellation parameter was provided when TessellationService.py was called, \texttt{tessellate{\textunderscore}wsi(slide, slide{\textunderscore}name, region)} is called. Otherwise, the BB is calculated via \texttt{get{\textunderscore}bounding{\textunderscore}box(region)}. If the -r parameter was provided, the BB will be adjusted to fit the supplied image ratio (via \texttt{resize{\textunderscore}bounding{\textunderscore}box(bounding{\textunderscore}box)}, see line 10 - 12). Then, the BB's position inside the baseline image of the provided WSI is determined (see line 13). Afterwards, the size of the BB is calculated for both dimension (see line 14). OpenSlide's \texttt{read{\textunderscore}region(location, level, size)} is used to access the ROI located at the specified position (the baseline image is at level 0\cite{DICOM10}, see line 15). The extracted image is then saved via the \texttt{save{\textunderscore}image(image, region, slide{\textunderscore}name)} function.

Once every region was extracted, the OpenSlide object is closed again.

\begin{lstlisting}[frame=single,language=python]
def wsi(file):
	slide = OpenSlide(file)
	slide_name = file.split('/')[-1]
	regions = read_json(file + '_' + DICTIONARY)
	
	for region in regions:
		if(TESSELLATE):
			tessellate_wsi(slide, slide_name, region)
		else:
			bounding_box = get_bounding_box(region)
			if(RESIZE):
				bounding_box = resize_bounding_box(bounding_box)
			location = (bounding_box['x_min'], bounding_box['y_min'])
			size = (bounding_box['x_max'] - bounding_box['x_min'], bounding_box['y_max'] - bounding_box['y_min'])
			image = slide.read_region(location, 0, size)
			save_image(image, region, slide_name)
	
	slide.close()
\end{lstlisting}


\subsubsection{tessellate{\textunderscore}wsi(slide, slide{\textunderscore}name, region)}
\texttt{tessellate{\textunderscore}wsi(slide, slide{\textunderscore}name, region)} realizes the approximation of a ROI through tessellation\footnote{
	Compare subsection \ref{sec5_tessellation}
}. To do so, it first gets the slide dimension to calculate the amount of virtual tiles necessary to cover the whole WSI (see line 2 - 4). Afterwards, a contour is created by iteration over every segment of a region's path and associating it with a virtual tile (see line 10 - 18). The result is a contour of virtual tiles.

In the next step, the RI is created. Each pixel in the RI corresponds to a virtual tile. Because of this relation between tiles and pixels, the created tile contour can be used to fill in the ROI in the RI via OpenCV's \texttt{cv2.drawContours(...)} function (see line 23). The provided parameters are:
\begin{itemize}
	\item \textbf{cv{\textunderscore}ref{\textunderscore}img}: the RI
	\item \textbf{[contour]}: the list of contours to draw
	\item \textbf{0}: which contour to draw from the provided array (0 equals all)
	\item \textbf{(255, 255, 255)}: a tupel with the color in which the contour is drawn in (white)
	\item \textbf{-1}: the stroke width of the contour (-1 equals fill)
\end{itemize}

The result is the RI where every pixel corresponding to a virtual tile in the ROI is white. In the next step, the function iterates over every single pixel of the RI and extracts a ROI into an individual image, whenever the corresponding pixel is white (see line 27 - 37).

After all tiles were extracted, an associated metadata file is created (see line 40).

\begin{lstlisting}[frame=single,language=python]
def tessellate_wsi(slide, slide_name, region):
	n,m = slide.dimensions
	m = m / TESSELLATE[HEIGHT]
	n = n / TESSELLATE[WIDTH]
	
	if SHOW:
		ox = 999999
		oy = 999999
	
	contour = []
	for coords in region.get('imgCoords'):
	if SHOW:
		if(coords.get('y') < oy): oy = coords.get('y')
		if(coords.get('x') < ox): ox = coords.get('x')
	x = int(coords.get('x') / TESSELLATE[WIDTH])
	y = int(coords.get('y') / TESSELLATE[HEIGHT])
	if [x, y] not in contour:
		contour.append([x, y])
	
	contour = np.asarray(contour)
	ref_img = Image.new('RGB', (n,m))
	cv_ref_img = np.array(ref_img)
	cv2.drawContours(cv_ref_img, [contour], 0, (255,255,255), -1)
	if SHOW:
		dbg_img = Image.new('RGB', (n,m))
	tiles = []
	for i in xrange(0, m):
		for j in xrange(0, n):
			px = cv_ref_img[i,j]
			if (px == [255, 255, 255]).all():
				location = ((j) * TESSELLATE[WIDTH], (i) * TESSELLATE[HEIGHT])
				size = TESSELLATE
				tile = slide.read_region(location, 0, size)
				tile_name = save_image(tile, region, slide_name, i, j)
				tiles.append(tile_name.split('/')[-1] + '.jpeg')
				if SHOW:
					dbg_img.paste(tile, (j * TESSELLATE[WIDTH] - int(ox), i * TESSELLATE[HEIGHT] - int(oy)))
	if SHOW:
	dbg_img.show()
	save_metadata(generate_file_name(region, slide_name), region, tiles)
\end{lstlisting}


\subsubsection{is{\textunderscore}supported(file)}
\texttt{is{\textunderscore}supported(file)} checks if a provided file is a proprietary WSI (see subsection \ref{sec2_proprietaryForams}).
\begin{lstlisting}[frame=single,language=python]
def is_suppoted(file):
	ext = (file.split('.'))[-1]
	if(
		'bif' in ext or
		'mrxs' in ext or
		'npdi' in ext or
		'scn' in ext or
		'svs' in ext or
		'svslide' in ext or
		'tif' in ext or
		'tiff' in ext or
		'vms' in ext or
		'vmu' in ext
	):
		return 1
	else:
		return 0
\end{lstlisting}


\section{DZI}

\subsubsection{dzi(file)}
\texttt{dzi(file)} extracts the regions from a DZI. Since OpenSlide can not be used with DZIs, the corresponding ROI must be stitched manually. To do so, the provided file's DZI metadata must be parsed to access the information about width, height, format and location of the highest resolution layer (see line 2 - 6). The saved regions are parsed with the \texttt{read{\textunderscore}json(path)} function (see line 7).

For each parsed region, an image is extracted together with a metadata file, like in the WSI scenario. If the tessellation parameter was provided when TessellationService.py was called, \texttt{tessellate{\textunderscore}dzi(dzi, slide{\textunderscore}name, region)} is called. Otherwise, the BB is calculated via \texttt{get{\textunderscore}bounding{\textunderscore}box(region)}. The tiles containing the ROI are stitched together and cropped to size in the \texttt{create{\textunderscore}image{\textunderscore}from{\textunderscore}tiles(dzi, bounding{\textunderscore}box)} function. The resulting image is saved via the \texttt{save{\textunderscore}image(image, region, slide{\textunderscore}name)} function (see line 10 - 15).

\begin{lstlisting}[frame=single,language=python]
def dzi(file):
	slide_name = file.split('/')[-1]
	with open(file, 'r') as dzi_file:
		content = dzi_file.read()
	root = ET.fromstring(content)
	dzi = {'tile_size': int(root.get('TileSize')), 'width': int(root[0].get('Width')), 'height': int(root[0].get('Height')), 'tile_source': get_tile_source(file), 'format': root.get('Format')}
	regions = read_json(file + '_' + DICTIONARY)
	
	for region in regions:
		if TESSELLATE:
			tessellate_dzi(dzi, slide_name, region)
		else:
		bounding_box = get_bounding_box(region)
		image = create_image_from_tiles(dzi, bounding_box)
		save_image(image, region, slide_name)
\end{lstlisting}


\subsubsection{create{\textunderscore}image{\textunderscore}from{\textunderscore}tiles(dzi, bounding{\textunderscore}box)}
\texttt{create{\textunderscore}image{\textunderscore}from{\textunderscore}tiles(dzi, bounding{\textunderscore}box)} stitches the tiles containing the ROI to extract together by utilizing the ROI's BB.

If the -r parameter was provided at the TS' execution, the BB will be adjusted to fit the provided image ratio. This also has influence on what tiles will be needed (see line 2 - 3). The stitching of the baseline image area is realized in \texttt{get{\textunderscore}tiles{\textunderscore}from{\textunderscore}bounding{\textunderscore}box(dzi, bounding{\textunderscore}box)} (see line 4). Once the tiles are stitched, the offset of the ROI's BB inside the stitched image is calculated (see line 6 - 7), as well as its corners (see line 9 - 12).

This information is used to crop the stitched image to the size of the ROI's BB.

\begin{lstlisting}[frame=single,language=python]
def create_image_from_tiles(dzi, bounding_box):
	if(RESIZE):
		bounding_box = resize_bounding_box(bounding_box)
	tile_image = get_tiles_from_bounding_box(dzi, bounding_box)
	
	offset_x = bounding_box['x_min']
	offset_y = bounding_box['y_min']
	
	x_min = bounding_box['x_min'] - offset_x
	x_max = bounding_box['x_max'] - offset_x
	y_min = bounding_box['y_min'] - offset_y
	y_max = bounding_box['y_max'] - offset_y
	
	return tile_image.crop((x_min, y_min, x_max, y_max))
\end{lstlisting}


\subsubsection{get{\textunderscore}tiles{\textunderscore}from{\textunderscore}bounding{\textunderscore}box(dzi, bounding{\textunderscore}box)}

\texttt{get{\textunderscore}tiles{\textunderscore}from{\textunderscore}bounding{\textunderscore}box(dzi, bounding{\textunderscore}box)} stitches together a baseline image area  based on the provided BB.

To do so, the corners of the BB are converted to tile positions (see line 2 - 5). Then, a new image is created which will hold the needed tiles (see line 7). All needed tiles are iterated in width and height and pasted into the corresponding postion of the holding image (see line 9 - 12).

The stitched image is then returned.

\begin{lstlisting}[frame=single,language=python]
def get_tiles_from_bounding_box(dzi, bounding_box):
	x_min = bounding_box['x_min'] / dzi['tile_size']
	x_max = bounding_box['x_max'] / dzi['tile_size']
	y_min = bounding_box['y_min'] / dzi['tile_size']
	y_max = bounding_box['y_max'] / dzi['tile_size']
	
	stitch = Image.new('RGB', ((x_max-x_min+1) * dzi['tile_size'], (y_max-y_min+1) * dzi['tile_size']))
	
	for i in range(x_min, x_max+1):
		for j in range(y_min, y_max+1):
			tile = Image.open(dzi['tile_source'] + str(i) + '_' + str(j) + '.' + dzi['format'])
			stitch.paste(tile, ((i - x_min) * dzi['tile_size'], (j - y_min) * dzi['tile_size']))
	return stitch
\end{lstlisting}


\subsubsection{get{\textunderscore}tile{\textunderscore}source(file)}
\texttt{get{\textunderscore}tile{\textunderscore}source(file)} finds the level with the highest resolution in a DZI's \emph{"{\textunderscore}files"} directory and builds a file path based on that.

\begin{lstlisting}[frame=single,language=python]
def get_tile_source(file):
	files_dir = file.replace('.dzi', '_files/')
	layers = os.listdir(files_dir)
	layers.remove('metadata.txt')
	layers = map(int, layers)
	return files_dir + str(max(layers)) + '/'
\end{lstlisting}


\subsubsection{tessellate{\textunderscore}dzi(dzi, slide{\textunderscore}name, region)}
\texttt{tessellate{\textunderscore}dzi(dzi, slide{\textunderscore}name, region)} works in the same way as \texttt{tessellate{\textunderscore}wsi(slide, slide{\textunderscore}name, region)}, except for the tile extraction (see line 26 - 35).

As in \texttt{dzi(file)}, a baseline image area must be stitched (see line 3). To extract a virtual tile from that stitched image, \texttt{tessellate{\textunderscore}dzi(dzi, slide{\textunderscore}name, region)} crops that stitched image to the size of the current virtual tile and saves this in an individual image.

Once all tiles are extracted, a metadata file is created (see line 43).

\begin{lstlisting}[frame=single,language=python]
def tessellate_dzi(dzi, slide_name, region):
	bounding_box = get_bounding_box(region)
	tile_image = get_tiles_from_bounding_box(dzi, bounding_box)
	
	offset_x = bounding_box['x_min']
	offset_y = bounding_box['y_min']
	
	n,m = tile_image.size
	
	m = m / TESSELLATE[HEIGHT]
	n = n / TESSELLATE[WIDTH]
	
	contour = []
	for coords in region.get('imgCoords'):
	x = int((coords.get('x') - offset_x) / TESSELLATE[WIDTH])
	y = int((coords.get('y') - offset_y) / TESSELLATE[HEIGHT])
	if [x, y] not in contour:
		contour.append([x, y])
	
	contour = np.asarray(contour)
	ref_img = Image.new('RGB', (n,m))
	cv_ref_img = np.array(ref_img)
	cv2.drawContours(cv_ref_img, [contour], 0, (255,255,255), -1)
	if SHOW:
		dbg_img = Image.new('RGB', tile_image.size)
	tiles = []
	for i in xrange(0, m):
		for j in xrange(0, n):
			px = cv_ref_img[i,j]
			if (px == [255, 255, 255]).all():
				tile = tile_image.crop((j * TESSELLATE[WIDTH] + (bounding_box['x_min'] % dzi['tile_size']),
				i * TESSELLATE[HEIGHT] + (bounding_box['y_min'] % dzi['tile_size']),
				j * TESSELLATE[WIDTH] + (bounding_box['x_min'] % dzi['tile_size']) + TESSELLATE[WIDTH],
				i * TESSELLATE[HEIGHT] + (bounding_box['y_min'] % dzi['tile_size']) + TESSELLATE[HEIGHT]))
				tile_name = save_image(tile, region, slide_name, i, j)
				tiles.append(tile_name.split('/')[-1] + '.jpeg')
				if SHOW:
					dbg_img.paste(tile, (j * TESSELLATE[WIDTH], i * TESSELLATE[HEIGHT]))
	if SHOW:
		dbg_img.show()
	save_metadata(generate_file_name(region, slide_name), region, tiles)
\end{lstlisting}


\section{Utility}

\subsubsection{read{\textunderscore}json(path)}

\begin{lstlisting}[frame=single,language=python]
def read_json(path):
	try:
		with open(path, 'r') as file:
		str = (file.read())
		data = json.loads(str.decode('utf-8'))
		return data
	except IOError:
		print('Could not load saved annotations from ' + path)
\end{lstlisting}


\subsubsection{save{\textunderscore}metadata(name, region, *tiles)}

\begin{lstlisting}[frame=single,language=python]
def save_metadata(name, region, *tiles):
	if len(tiles) > 0:
	name = name + '_tessellated.metadata.json'
	if not FORCE:
		cnt = 0
		while os.path.isfile(name):
			cnt+=1
		name = name + '(' + str(cnt) +')'
	else:
		image_name = name
	name = name + '.metadata.json'
	with open(name, 'w+') as file:
		data = {'label': region.get('name'), 'zoom': region.get('zoom'), 'context': region.get('context')}
	if len(tiles) > 0:
		data['tiles'] = tiles
	else:
		data['image'] = image_name.split('/')[-1] + '.jpeg'
	content = json.dumps(data, ensure_ascii=False)
	file.write(content.encode('utf-8'))
\end{lstlisting}


\subsubsection{generate{\textunderscore}file{\textunderscore}name(region, slide{\textunderscore}name, *tiles)}

\begin{lstlisting}[frame=single,language=python]
def generate_file_name(region, slide_name, *tiles):
	if(OUTPUT):
		dest = OUTPUT + region['name']
	else:
		dest = region['name']
	if not os.path.exists(dest):
		os.makedirs(dest)
	name = dest + '/' + slide_name + '_' + str(region['uid'])
	if len(tiles) > 0:
		for entry in tiles:
			name += "_" + str(entry)
	if not FORCE:
		cnt = 0
		while os.path.isfile(name):
			cnt+=1
		name = name + '(' + str(cnt) +')'
	return name
\end{lstlisting}


\subsubsection{save{\textunderscore}image(image, region, slide{\textunderscore}name, *tiles}

\begin{lstlisting}[frame=single,language=python]
def save_image(image, region, slide_name, *tiles):
	if len(tiles) == 0:
		name = generate_file_name(region, slide_name)
	else:
		name = generate_file_name(region, slide_name, tiles)
	if RESIZE:
		image = image.resize(RESIZE, INTERPOLATION)
	# L = R * 299/1000 + G * 587/1000 + B * 114/1000
	if GRAYSCALE:
		image = image.convert('L')
	image.save(name + '.jpeg', 'jpeg')
	if len(tiles) == 0:
		save_metadata(name, region)
	return name
\end{lstlisting}


\subsubsection{get{\textunderscore}bounding{\textunderscore}box(region)}

\begin{lstlisting}[frame=single,language=python]
def get_bounding_box(region):
	x_min = sys.float_info.max
	x_max = sys.float_info.min
	y_min = x_min
	y_max = x_max
	for coordinate in region.get('imgCoords'):
		x = coordinate.get('x')
		y = coordinate.get('y')
		if(x >= x_max):
			x_max = x
		if(x < x_min) :
			x_min = x
		if(y >= y_max):
			y_max = y
		if(y < y_min) :
			y_min = y
	
	return {'x_max': int(np.ceil(x_max)), 'x_min': int(np.floor(x_min)),
		'y_max': int(np.ceil(y_max)), 'y_min': int(np.floor(y_min))}
\end{lstlisting}


\subsubsection{resize{\textunderscore}bounding{\textunderscore}box(region)}

\begin{lstlisting}[frame=single,language=python]
def resize_bounding_box(bounding_box):
	r_ratio = RESIZE[WIDTH] / float(RESIZE[HEIGHT])
	bb_width = float(bounding_box['x_max'] - bounding_box['x_min'])
	bb_height = float(bounding_box['y_max'] - bounding_box['y_min'])
	bb_ratio = bb_width / bb_height
	if r_ratio == bb_ratio:
		return bounding_box
	else:
		if r_ratio == 1:
			# target is square
			s1 = bb_height/bb_width
			s2 = bb_width/bb_height
			scaled = min(bb_width, bb_height) * max(s1, s2) - min(bb_width, bb_height)
			if(bb_width > bb_height):
				bounding_box['y_min'] -= int(np.floor(scaled/2))
				bounding_box['y_max'] += int(np.ceil(scaled/2))
			else:
				bounding_box['x_min'] -= int(np.floor(scaled/2))
				bounding_box['x_max'] += int(np.ceil(scaled/2))
		elif r_ratio < 1:
			# target is higher than wide
			h_s = 1 / r_ratio
			if bb_height > (bb_width * h_s):
				# adjust width:
				w_new = (bb_height / h_s) - bb_width
				bounding_box['x_min'] -= int(np.floor(w_new/2))
				bounding_box['x_max'] += int(np.ceil(w_new/2))
			else:
				# adjust height:
				h_new = h_s * bb_width - bb_height
				bounding_box['y_min'] -= int(np.floor(h_new/2))
				bounding_box['y_max'] += int(np.ceil(h_new/2))
		else:
			# target is wider than high
			w_s = r_ratio
			if bb_width > (bb_height * w_s):
				# adjust height
				h_new = (bb_width / w_s) - bb_height
				bounding_box['y_min'] -= int(np.floor(h_new/2))
				bounding_box['y_max'] += int(np.ceil(h_new/2))
			else:
				# adjust width:
				w_new = w_s * bb_height - bb_width
				bounding_box['x_min'] -= int(np.floor(w_new/2))
				bounding_box['x_max'] += int(np.ceil(w_new/2))
		
		# check if bb is big enough
		bb_width = float(bounding_box['x_max'] - bounding_box['x_min'])
		if bb_width < RESIZE[WIDTH]:
			s = RESIZE[WIDTH] / bb_width
			bounding_box = scale_bounding_box(bounding_box, s)
		bb_height = float(bounding_box['y_max'] - bounding_box['y_min'])
		if bb_height < RESIZE[HEIGHT]:
			s = RESIZE[HEIGHT] / bb_height
			bounding_box = scale_bounding_box(bounding_box, s)
		
		if(bounding_box['y_min'] < 0):
			dif = bounding_box['y_min'] * (-1)
			bounding_box['y_min'] += dif
			bounding_box['y_max'] += dif
		if(bounding_box['x_min'] < 0):
			dif = bounding_box['x_min'] * (-1)
			bounding_box['x_min'] += dif
			bounding_box['x_max'] += dif
	
		return bounding_box
\end{lstlisting}


\subsubsection{scale{\textunderscore}bounding{\textunderscore}box(bounding{\textunderscore}, scale)}

\begin{lstlisting}[frame=single,language=python]
def scale_bounding_box(bounding_box, scale):
	bb_width = float(bounding_box['x_max'] - bounding_box['x_min'])
	add_w = (bb_width * scale) - bb_width
	bounding_box['x_min'] -= int(np.floor(add_w/2))
	bounding_box['x_max'] += int(np.ceil(add_w/2))
	
	bb_height = float(bounding_box['y_max'] - bounding_box['y_min'])
	add_h = (bb_height * scale) - bb_height
	bounding_box['y_min'] -= int(np.floor(add_h/2))
	bounding_box['y_max'] += int(np.ceil(add_h/2))
	
	return bounding_box
\end{lstlisting}